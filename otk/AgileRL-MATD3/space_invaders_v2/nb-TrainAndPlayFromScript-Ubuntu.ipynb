{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4488f4",
   "metadata": {},
   "source": [
    "# AgileRL Space Invaders with MATD3\n",
    "https://docs.agilerl.com/en/latest/tutorials/pettingzoo/matd3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc69b66d-50af-4ab2-9c4b-8370ecd819d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b039f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba031e05-4822-4ce2-acfb-0cf92b11910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.2\n",
      "  Using cached numpy-1.24.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.2-cp310-cp310-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6670f3ca-a919-4345-b839-ddc3eb2f55c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supersuit==3.9.0\n",
      "  Using cached SuperSuit-3.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from supersuit==3.9.0) (1.24.2)\n",
      "Collecting gymnasium>=0.28.1 (from supersuit==3.9.0)\n",
      "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tinyscaler>=1.2.6 (from supersuit==3.9.0)\n",
      "  Using cached tinyscaler-1.2.7-cp310-cp310-macosx_11_0_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium>=0.28.1->supersuit==3.9.0)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium>=0.28.1->supersuit==3.9.0) (4.10.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.1->supersuit==3.9.0)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Using cached SuperSuit-3.9.0-py3-none-any.whl (49 kB)\n",
      "Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "Using cached tinyscaler-1.2.7-cp310-cp310-macosx_11_0_x86_64.whl (96 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, tinyscaler, cloudpickle, gymnasium, supersuit\n",
      "Successfully installed cloudpickle-3.0.0 farama-notifications-0.0.4 gymnasium-0.29.1 supersuit-3.9.0 tinyscaler-1.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install supersuit==3.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffde7aa6-7e95-4624-9bbc-fe76009a7953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pettingzoo==1.23.1 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached pettingzoo-1.23.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from pettingzoo==1.23.1->pettingzoo[atari,classic,mpe]==1.23.1) (1.24.2)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from pettingzoo==1.23.1->pettingzoo[atari,classic,mpe]==1.23.1) (0.29.1)\n",
      "Collecting pygame==2.3.0 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached pygame-2.3.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (10 kB)\n",
      "Collecting multi-agent-ale-py==0.1.11 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached multi_agent_ale_py-0.1.11-cp310-cp310-macosx_14_0_x86_64.whl\n",
      "Collecting chess==1.7.0 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached chess-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rlcard==1.0.5 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached rlcard-1.0.5-py3-none-any.whl\n",
      "Collecting hanabi-learning-environment==0.0.4 (from pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached hanabi_learning_environment-0.0.4-cp310-cp310-macosx_14_0_x86_64.whl\n",
      "Requirement already satisfied: cffi in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from hanabi-learning-environment==0.0.4->pettingzoo[atari,classic,mpe]==1.23.1) (1.16.0)\n",
      "Collecting termcolor (from rlcard==1.0.5->pettingzoo[atari,classic,mpe]==1.23.1)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo==1.23.1->pettingzoo[atari,classic,mpe]==1.23.1) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo==1.23.1->pettingzoo[atari,classic,mpe]==1.23.1) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium>=0.28.0->pettingzoo==1.23.1->pettingzoo[atari,classic,mpe]==1.23.1) (0.0.4)\n",
      "Requirement already satisfied: pycparser in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from cffi->hanabi-learning-environment==0.0.4->pettingzoo[atari,classic,mpe]==1.23.1) (2.21)\n",
      "Using cached pettingzoo-1.23.1-py3-none-any.whl (826 kB)\n",
      "Using cached chess-1.7.0-py3-none-any.whl (147 kB)\n",
      "Using cached pygame-2.3.0-cp310-cp310-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: termcolor, pygame, multi-agent-ale-py, chess, rlcard, pettingzoo, hanabi-learning-environment\n",
      "Successfully installed chess-1.7.0 hanabi-learning-environment-0.0.4 multi-agent-ale-py-0.1.11 pettingzoo-1.23.1 pygame-2.3.0 rlcard-1.0.5 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install pettingzoo==1.23.1\n",
    "!pip install \"\"\"pettingzoo[classic,atari,mpe]==1.23.1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebab40c-0002-49bd-ba96-16a3803f71ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting agilerl==0.1.16\n",
      "  Using cached agilerl-0.1.16-py3-none-any.whl.metadata (62 kB)\n",
      "Requirement already satisfied: SuperSuit<4.0.0,>=3.9.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from agilerl==0.1.16) (3.9.0)\n",
      "Collecting accelerate<0.19.0,>=0.18.0 (from agilerl==0.1.16)\n",
      "  Using cached accelerate-0.18.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting dill<0.4.0,>=0.3.7 (from agilerl==0.1.16)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fastrand<2.0.0,>=1.3.0 (from agilerl==0.1.16)\n",
      "  Using cached fastrand-1.8.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting flatten_dict<0.5.0,>=0.4.2 (from agilerl==0.1.16)\n",
      "  Using cached flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting gymnasium<0.29.0,>=0.28.1 (from agilerl==0.1.16)\n",
      "  Using cached gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting h5py<4.0.0,>=3.8.0 (from agilerl==0.1.16)\n",
      "  Using cached h5py-3.10.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting hydra-core<2.0.0,>=1.3.2 (from agilerl==0.1.16)\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting importlib<2.0.0,>=1.0.4 (from agilerl==0.1.16)\n",
      "  Using cached importlib-1.0.4-py3-none-any.whl\n",
      "Collecting matplotlib<4.0.0,>=3.4.3 (from agilerl==0.1.16)\n",
      "  Using cached matplotlib-3.8.3-cp310-cp310-macosx_10_12_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting minari<0.5.0,>=0.4.1 (from agilerl==0.1.16)\n",
      "  Using cached minari-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from agilerl==0.1.16) (1.24.2)\n",
      "Collecting omegaconf<3.0.0,>=2.3.0 (from agilerl==0.1.16)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pettingzoo<2.0.0,>=1.23.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from agilerl==0.1.16) (1.23.1)\n",
      "Collecting pre-commit<4.0.0,>=3.4.0 (from agilerl==0.1.16)\n",
      "  Using cached pre_commit-3.6.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting redis<5.0.0,>=4.4.4 (from agilerl==0.1.16)\n",
      "  Using cached redis-4.6.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting termcolor<2.0.0,>=1.1.0 (from agilerl==0.1.16)\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting torch<3.0.0,>=2.0.1 (from agilerl==0.1.16)\n",
      "  Using cached torch-2.2.1-cp310-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting tqdm<5.0.0,>=4.65.0 (from agilerl==0.1.16)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers<5.0.0,>=4.30.0 (from agilerl==0.1.16)\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "Collecting wandb<0.14.0,>=0.13.10 (from agilerl==0.1.16)\n",
      "  Using cached wandb-0.13.11-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl==0.1.16) (24.0)\n",
      "Requirement already satisfied: psutil in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl==0.1.16) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from accelerate<0.19.0,>=0.18.0->agilerl==0.1.16) (6.0.1)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from flatten_dict<0.5.0,>=0.4.2->agilerl==0.1.16) (1.16.0)\n",
      "Collecting jax-jumpy>=1.0.0 (from gymnasium<0.29.0,>=0.28.1->agilerl==0.1.16)\n",
      "  Using cached jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl==0.1.16) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl==0.1.16) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from gymnasium<0.29.0,>=0.28.1->agilerl==0.1.16) (0.0.4)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<2.0.0,>=1.3.2->agilerl==0.1.16)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached fonttools-4.50.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (159 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.4.3->agilerl==0.1.16) (2.9.0.post0)\n",
      "Collecting google-cloud-storage>=2.5.0 (from minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typer>=0.9.0 (from typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting portion>=2.4.0 (from minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached portion-2.4.2-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16)\n",
      "  Using cached cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16)\n",
      "  Using cached identify-2.5.35-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16)\n",
      "  Using cached nodeenv-1.8.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16)\n",
      "  Using cached virtualenv-20.25.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting async-timeout>=4.0.2 (from redis<5.0.0,>=4.4.4->agilerl==0.1.16)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tinyscaler>=1.2.6 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from SuperSuit<4.0.0,>=3.9.0->agilerl==0.1.16) (1.2.7)\n",
      "Collecting filelock (from torch<3.0.0,>=2.0.1->agilerl==0.1.16)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sympy (from torch<3.0.0,>=2.0.1->agilerl==0.1.16)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch<3.0.0,>=2.0.1->agilerl==0.1.16)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from torch<3.0.0,>=2.0.1->agilerl==0.1.16) (3.1.3)\n",
      "Collecting fsspec (from torch<3.0.0,>=2.0.1->agilerl==0.1.16)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers<5.0.0,>=4.30.0->agilerl==0.1.16)\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.30.0->agilerl==0.1.16)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from transformers<5.0.0,>=4.30.0->agilerl==0.1.16) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.30.0->agilerl==0.1.16)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.30.0->agilerl==0.1.16)\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting Click!=8.0.0,>=7.0 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached sentry_sdk-1.43.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pathtools (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Collecting setproctitle (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached setproctitle-1.3.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16) (69.2.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting google-auth<3.0dev,>=2.26.1 (from google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_auth-2.28.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached google_crc32c-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting sortedcontainers~=2.2 (from portion>=2.4.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.30.0->agilerl==0.1.16) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.30.0->agilerl==0.1.16) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.30.0->agilerl==0.1.16) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.30.0->agilerl==0.1.16) (2024.2.2)\n",
      "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich<14.0.0,>=10.11.0 (from typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16)\n",
      "  Using cached distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit<4.0.0,>=3.4.0->agilerl==0.1.16) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.0.1->agilerl==0.1.16) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch<3.0.0,>=2.0.1->agilerl==0.1.16)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb<0.14.0,>=0.13.10->agilerl==0.1.16)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]>=0.9.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->minari<0.5.0,>=0.4.1->agilerl==0.1.16)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached agilerl-0.1.16-py3-none-any.whl (177 kB)\n",
      "Using cached accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fastrand-1.8.0-cp310-cp310-macosx_10_9_x86_64.whl (9.1 kB)\n",
      "Using cached flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Using cached gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "Using cached h5py-3.10.0-cp310-cp310-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached matplotlib-3.8.3-cp310-cp310-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "Using cached minari-0.4.3-py3-none-any.whl (42 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached pre_commit-3.6.2-py2.py3-none-any.whl (204 kB)\n",
      "Using cached redis-4.6.0-py3-none-any.whl (241 kB)\n",
      "Using cached torch-2.2.1-cp310-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Using cached wandb-0.13.11-py3-none-any.whl (2.0 MB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached contourpy-1.2.0-cp310-cp310-macosx_10_9_x86_64.whl (256 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached fonttools-4.50.0-cp310-cp310-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Using cached google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "Using cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached identify-2.5.35-py2.py3-none-any.whl (98 kB)\n",
      "Using cached jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl (68 kB)\n",
      "Using cached nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached portion-2.4.2-py3-none-any.whl (27 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\n",
      "Using cached safetensors-0.4.2-cp310-cp310-macosx_10_12_x86_64.whl (426 kB)\n",
      "Using cached sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Using cached virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached setproctitle-1.3.3-cp310-cp310-macosx_10_9_x86_64.whl (11 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "Using cached google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_crc32c-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\n",
      "Using cached google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Installing collected packages: termcolor, sortedcontainers, pathtools, mpmath, importlib, fastrand, distlib, appdirs, antlr4-python3-runtime, tqdm, sympy, smmap, shellingham, setproctitle, sentry-sdk, safetensors, regex, pyparsing, pyasn1, protobuf, portion, pillow, omegaconf, nodeenv, networkx, mdurl, kiwisolver, jax-jumpy, identify, h5py, google-crc32c, fsspec, fonttools, flatten_dict, filelock, docker-pycreds, dill, cycler, contourpy, colorama, Click, cfgv, cachetools, async-timeout, virtualenv, typer, torch, rsa, redis, pyasn1-modules, matplotlib, markdown-it-py, hydra-core, huggingface-hub, gymnasium, googleapis-common-protos, google-resumable-media, gitdb, tokenizers, rich, pre-commit, google-auth, GitPython, accelerate, wandb, transformers, google-api-core, google-cloud-core, google-cloud-storage, minari, agilerl\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.4.0\n",
      "    Uninstalling termcolor-2.4.0:\n",
      "      Successfully uninstalled termcolor-2.4.0\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 0.29.1\n",
      "    Uninstalling gymnasium-0.29.1:\n",
      "      Successfully uninstalled gymnasium-0.29.1\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.42 accelerate-0.18.0 agilerl-0.1.16 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 async-timeout-4.0.3 cachetools-5.3.3 cfgv-3.4.0 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 dill-0.3.8 distlib-0.3.8 docker-pycreds-0.4.0 fastrand-1.8.0 filelock-3.13.1 flatten_dict-0.4.2 fonttools-4.50.0 fsspec-2024.3.1 gitdb-4.0.11 google-api-core-2.17.1 google-auth-2.28.2 google-cloud-core-2.4.1 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 gymnasium-0.28.1 h5py-3.10.0 huggingface-hub-0.21.4 hydra-core-1.3.2 identify-2.5.35 importlib-1.0.4 jax-jumpy-1.0.0 kiwisolver-1.4.5 markdown-it-py-3.0.0 matplotlib-3.8.3 mdurl-0.1.2 minari-0.4.3 mpmath-1.3.0 networkx-3.2.1 nodeenv-1.8.0 omegaconf-2.3.0 pathtools-0.1.2 pillow-10.2.0 portion-2.4.2 pre-commit-3.6.2 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 pyparsing-3.1.2 redis-4.6.0 regex-2023.12.25 rich-13.7.1 rsa-4.9 safetensors-0.4.2 sentry-sdk-1.43.0 setproctitle-1.3.3 shellingham-1.5.4 smmap-5.0.1 sortedcontainers-2.4.0 sympy-1.12 termcolor-1.1.0 tokenizers-0.15.2 torch-2.2.1 tqdm-4.66.2 transformers-4.38.2 typer-0.9.0 virtualenv-20.25.1 wandb-0.13.11\n"
     ]
    }
   ],
   "source": [
    "!pip install agilerl==0.1.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7f6911-80b3-4924-a646-d109b2322441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autorom==0.6.1\n",
      "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: click in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from autorom==0.6.1) (8.1.7)\n",
      "Requirement already satisfied: requests in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from autorom==0.6.1) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->autorom==0.6.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->autorom==0.6.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->autorom==0.6.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from requests->autorom==0.6.1) (2024.2.2)\n",
      "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: autorom\n",
      "Successfully installed autorom-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install autorom==0.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7d0759-58a8-4e81-a8af-bed68b84eabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoROM will download the Atari 2600 ROMs.\n",
      "They will be installed to:\n",
      "\t/Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms\n",
      "\t/Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms\n",
      "\n",
      "Existing ROMs will be overwritten.\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/adventure.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/adventure.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/air_raid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/air_raid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/alien.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/alien.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/amidar.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/amidar.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/assault.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/assault.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/asterix.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/asterix.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/asteroids.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/asteroids.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/atlantis.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/atlantis.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/atlantis2.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/backgammon.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/backgammon.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/bank_heist.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/basic_math.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/basic_math.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/battle_zone.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/beam_rider.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/berzerk.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/berzerk.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/blackjack.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/blackjack.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/bowling.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/bowling.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/boxing.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/boxing.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/breakout.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/breakout.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/carnival.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/carnival.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/casino.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/casino.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/centipede.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/centipede.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/chopper_command.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/combat.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/combat.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/crazy_climber.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/crossbow.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/crossbow.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/darkchambers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/defender.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/defender.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/demon_attack.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/donkey_kong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/double_dunk.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/earthworld.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/earthworld.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/elevator_action.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/enduro.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/enduro.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/entombed.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/entombed.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/et.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/et.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/fishing_derby.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/flag_capture.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/freeway.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/freeway.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/frogger.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/frogger.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/frostbite.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/frostbite.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/galaxian.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/galaxian.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/gopher.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/gopher.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/gravitar.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/gravitar.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/hangman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/hangman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/haunted_house.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/hero.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/hero.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/human_cannonball.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/ice_hockey.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/jamesbond.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/journey_escape.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/joust.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/joust.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/kaboom.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/kaboom.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/kangaroo.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/keystone_kapers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/king_kong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/king_kong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/klax.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/klax.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/koolaid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/koolaid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/krull.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/krull.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/kung_fu_master.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/laser_gates.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/lost_luggage.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/mario_bros.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/maze_craze.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/miniature_golf.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/montezuma_revenge.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/mr_do.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/mr_do.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/ms_pacman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/name_this_game.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/othello.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/othello.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/pacman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/pacman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/phoenix.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/phoenix.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/pitfall.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/pitfall.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/pitfall2.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/pong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/pong.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/pooyan.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/pooyan.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/private_eye.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/private_eye.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/qbert.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/qbert.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/riverraid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/riverraid.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/road_runner.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/road_runner.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/robotank.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/robotank.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/seaquest.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/seaquest.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/sir_lancelot.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/skiing.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/skiing.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/solaris.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/solaris.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/space_invaders.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/space_war.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/space_war.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/star_gunner.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/superman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/superman.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/surround.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/surround.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/tennis.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/tennis.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/tetris.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/tetris.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/time_pilot.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/trondead.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/trondead.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/turmoil.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/turmoil.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/tutankham.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/tutankham.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/up_n_down.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/venture.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/venture.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/video_checkers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/video_chess.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/video_chess.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/video_cube.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/video_cube.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/video_pinball.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/warlords.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/warlords.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/wizard_of_wor.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/word_zapper.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/yars_revenge.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/AutoROM/roms/zaxxon.bin\n",
      "Installed /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!AutoROM -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e121a0f9-1465-4554-b1ea-3037edee934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from imageio) (1.24.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/work/work-DRLLSS2024/venv-atari/lib/python3.10/site-packages (from imageio) (10.2.0)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "650780a5-3d68-4be5-86f0-c82da80a1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240325-0509\n"
     ]
    }
   ],
   "source": [
    "#現在日時を取得\n",
    "import datetime\n",
    "\n",
    "if True: #新規採番\n",
    "    dt_now = datetime.datetime.now()\n",
    "    str_dt_now = dt_now.strftime(\"%Y%m%d-%H%M\")\n",
    "    print(str_dt_now)\n",
    "\n",
    "else: # 固定値\n",
    "    str_dt_now = \"20231231-1733\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "947fe8d6-7155-469c-8ee5-462ded068335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b763bc86-f7c4-4ab5-adf3-98068042f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start  :  20240325-0509\n",
      "===== AgileRL Online Multi-Agent Demo =====\n",
      "state_dim [(4, 84, 84), (4, 84, 84)]\n",
      "action_dim [6, 6]\n",
      "one_hot False\n",
      "NET_CONFIG\n",
      "{'arch': 'cnn',\n",
      " 'c_size': [3, 32],\n",
      " 'h_size': [32, 32],\n",
      " 'k_size': [[1, 3, 3], [1, 3, 3]],\n",
      " 'normalize': 'True',\n",
      " 's_size': [2, 2]}\n",
      "INIT_HP\n",
      "{'AGENT_IDS': ['first_0', 'second_0'],\n",
      " 'ALGO': 'MATD3',\n",
      " 'BATCH_SIZE': 64,\n",
      " 'CHANNELS_LAST': 'True',\n",
      " 'DISCRETE_ACTIONS': True,\n",
      " 'GAMMA': 0.95,\n",
      " 'LEARN_STEP': 5,\n",
      " 'LR': 0.01,\n",
      " 'MAX_ACTION': None,\n",
      " 'MEMORY_SIZE': 200000,\n",
      " 'MIN_ACTION': None,\n",
      " 'N_AGENTS': 2,\n",
      " 'POLICY_FREQ': 2,\n",
      " 'POPULATION_SIZE': 1,\n",
      " 'TAU': 0.01}\n",
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                 | 49/5000 [00:54<1:41:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.33']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                                | 99/5000 [02:00<1:45:43,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▉                                                                                              | 149/5000 [03:07<1:47:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 150/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                             | 199/5000 [04:16<1:51:34,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.25']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                            | 249/5000 [05:23<1:43:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250/5000\n",
      "Fitnesses: ['0.67']\n",
      "100 fitness avgs: ['1.93']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                           | 299/5000 [06:31<1:51:21,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.06']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▊                                                                                          | 349/5000 [07:41<1:45:22,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 350/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.24']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▋                                                                                         | 399/5000 [08:50<1:47:11,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 400/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▋                                                                                        | 449/5000 [10:02<1:45:50,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 450/5000\n",
      "Fitnesses: ['3.67']\n",
      "100 fitness avgs: ['2.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                       | 499/5000 [11:09<1:38:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.33']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▋                                                                                      | 549/5000 [12:20<1:38:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 550/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▌                                                                                     | 599/5000 [13:32<1:47:49,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.31']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▌                                                                                    | 649/5000 [14:45<1:41:58,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 650/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.38']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▌                                                                                   | 699/5000 [15:56<1:41:11,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████▌                                                                                  | 749/5000 [17:09<1:37:39,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 750/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▌                                                                                 | 799/5000 [18:20<1:41:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 800/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.44']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████▍                                                                                | 849/5000 [19:31<1:39:40,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 850/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.37']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▍                                                                               | 899/5000 [20:44<1:36:29,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 900/5000\n",
      "Fitnesses: ['4.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████▍                                                                              | 949/5000 [22:00<1:40:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 950/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.44']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▍                                                                             | 999/5000 [23:11<1:33:52,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000/5000\n",
      "Fitnesses: ['4.00']\n",
      "100 fitness avgs: ['2.52']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████▏                                                                           | 1049/5000 [24:22<1:25:22,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1050/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████                                                                           | 1099/5000 [25:27<1:23:23,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1100/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████                                                                          | 1149/5000 [26:32<1:22:23,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1150/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.51']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████                                                                         | 1199/5000 [27:37<1:23:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1200/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▉                                                                        | 1249/5000 [28:44<1:23:20,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1250/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▉                                                                       | 1299/5000 [29:51<1:21:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1300/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████████▉                                                                      | 1349/5000 [30:56<1:18:09,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1350/5000\n",
      "Fitnesses: ['4.33']\n",
      "100 fitness avgs: ['2.56']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▊                                                                     | 1399/5000 [32:02<1:16:46,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1400/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.54']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████▊                                                                    | 1449/5000 [33:07<1:16:08,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1450/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.53']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▊                                                                   | 1499/5000 [34:12<1:13:39,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1500/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████▋                                                                  | 1549/5000 [35:16<1:12:53,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1550/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.52']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▋                                                                 | 1599/5000 [36:20<1:12:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1600/5000\n",
      "Fitnesses: ['3.67']\n",
      "100 fitness avgs: ['2.55']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████▋                                                                | 1649/5000 [37:25<1:10:45,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1650/5000\n",
      "Fitnesses: ['3.67']\n",
      "100 fitness avgs: ['2.59']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████▌                                                               | 1699/5000 [38:29<1:09:34,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1700/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.56']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████▌                                                              | 1749/5000 [39:34<1:10:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1750/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.53']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████▌                                                             | 1799/5000 [40:38<1:07:32,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1800/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████▌                                                            | 1849/5000 [41:42<1:06:42,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1850/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.51']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████▍                                                           | 1899/5000 [42:46<1:05:30,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1900/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████████▍                                                          | 1949/5000 [43:51<1:04:34,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1950/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▍                                                         | 1999/5000 [44:55<1:03:27,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2000/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████▎                                                        | 2049/5000 [46:00<1:02:38,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2050/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████▎                                                       | 2099/5000 [47:05<1:01:38,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2100/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████▎                                                      | 2149/5000 [48:10<1:00:39,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2150/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.52']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████                                                       | 2199/5000 [49:14<59:26,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2200/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████████                                                      | 2249/5000 [50:19<58:49,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2250/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████                                                     | 2299/5000 [51:24<57:52,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2300/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████████                                                    | 2349/5000 [52:29<56:32,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2350/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████████                                                   | 2399/5000 [53:33<55:25,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2400/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████████████████████████████████                                                  | 2449/5000 [54:38<54:10,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2450/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████▉                                                 | 2499/5000 [55:43<53:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2500/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████████████▉                                                | 2549/5000 [56:47<51:48,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2550/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████▉                                               | 2599/5000 [57:52<50:57,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2600/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████████████▉                                              | 2649/5000 [58:56<49:47,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2650/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████▊                                            | 2699/5000 [1:00:01<48:52,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2700/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████████████▊                                           | 2749/5000 [1:01:05<47:33,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2750/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████▋                                          | 2799/5000 [1:02:09<46:27,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2800/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████▋                                         | 2849/5000 [1:03:13<45:30,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2850/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████████████▋                                        | 2899/5000 [1:04:18<44:24,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2900/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████████████████▌                                       | 2949/5000 [1:05:22<43:23,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2950/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████▌                                      | 2999/5000 [1:06:27<42:26,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3000/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████████████▌                                     | 3049/5000 [1:07:31<41:11,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3050/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████████████▌                                    | 3099/5000 [1:08:35<40:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3100/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████████████████████▍                                   | 3149/5000 [1:09:39<39:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3150/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████████████████▍                                  | 3199/5000 [1:10:43<37:53,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3200/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.44']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████████████████▍                                 | 3249/5000 [1:11:48<37:07,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3250/5000\n",
      "Fitnesses: ['1.33']\n",
      "100 fitness avgs: ['2.43']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████████████████████████████▎                                | 3299/5000 [1:12:52<35:58,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3300/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.44']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████▎                               | 3349/5000 [1:13:57<35:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3350/5000\n",
      "Fitnesses: ['3.67']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████████████▎                              | 3399/5000 [1:15:01<33:46,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3400/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████████████▏                             | 3449/5000 [1:16:05<32:50,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3450/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████▏                            | 3499/5000 [1:17:10<31:57,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3500/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████████████▏                           | 3549/5000 [1:18:14<30:53,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3550/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████████████                           | 3599/5000 [1:19:19<29:49,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3600/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████                          | 3649/5000 [1:20:23<28:34,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3650/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████████████                         | 3699/5000 [1:21:27<27:36,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3700/5000\n",
      "Fitnesses: ['3.67']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████▉                        | 3749/5000 [1:22:32<26:36,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3750/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████▉                       | 3799/5000 [1:23:37<25:33,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3800/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████▉                      | 3849/5000 [1:24:41<24:12,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3850/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████████████▊                     | 3899/5000 [1:25:45<23:24,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3900/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████████████▊                    | 3949/5000 [1:26:50<22:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3950/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████▊                   | 3999/5000 [1:27:54<21:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4000/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████▋                  | 4049/5000 [1:28:59<20:22,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4050/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.49']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████████████▋                 | 4099/5000 [1:30:04<19:11,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4100/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████▋                | 4149/5000 [1:31:09<18:07,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4150/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████▌               | 4199/5000 [1:32:14<17:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4200/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████████████████▌              | 4249/5000 [1:33:18<16:04,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4250/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.48']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████████████████▌             | 4299/5000 [1:34:23<15:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4300/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████████████▌            | 4349/5000 [1:35:28<13:56,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4350/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████▍           | 4399/5000 [1:36:33<12:53,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4400/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████████████████▍          | 4449/5000 [1:37:38<11:45,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4450/5000\n",
      "Fitnesses: ['3.33']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████▍         | 4499/5000 [1:38:42<10:42,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4500/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████████████████████████████▎        | 4549/5000 [1:39:47<09:38,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4550/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████████████████████▎       | 4599/5000 [1:40:53<08:33,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4600/5000\n",
      "Fitnesses: ['1.67']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████▎      | 4649/5000 [1:41:57<07:29,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4650/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████▏     | 4699/5000 [1:43:02<06:25,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4700/5000\n",
      "Fitnesses: ['3.00']\n",
      "100 fitness avgs: ['2.46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████▏    | 4749/5000 [1:44:07<05:21,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4750/5000\n",
      "Fitnesses: ['2.00']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████▏   | 4799/5000 [1:45:12<04:16,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4800/5000\n",
      "Fitnesses: ['2.67']\n",
      "100 fitness avgs: ['2.45']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████████████████████   | 4849/5000 [1:46:17<03:12,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4850/5000\n",
      "Fitnesses: ['4.00']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████  | 4899/5000 [1:47:21<02:08,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4900/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████ | 4949/5000 [1:48:26<01:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4950/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.47']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████▉| 4999/5000 [1:49:31<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5000/5000\n",
      "Fitnesses: ['2.33']\n",
      "100 fitness avgs: ['2.47']\n",
      "Save Model at ep  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [1:49:34<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Files...\n",
      "Done.\n",
      "Start  :  20240325-0509\n",
      "End    :  20240325-0658\n",
      "Elapse :  1:49:35.586032\n"
     ]
    }
   ],
   "source": [
    "dt_start = datetime.datetime.now()\n",
    "print(\"Start  : \", dt_start.strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "if False: # 続きから実行\n",
    "    path_p = \"./result/20231231-1732/pickle-population.pkl\"\n",
    "    path_r = \"./result/20231231-1732/pickle-replaybuffer.pkl\"\n",
    "    path_t = \"./result/20231231-1732/pickle-tournament.pkl\"\n",
    "    path_m = \"./result/20231231-1732/pickle-mutations.pkl\"\n",
    "\n",
    "    %run script-1-train.py -dt $str_dt_now -pop $path_p -r $path_r -t $path_t -m $path_m\n",
    "\n",
    "else: # 新規実行\n",
    "\n",
    "    %run script-1-train.py -dt $str_dt_now\n",
    "\n",
    "dt_end = datetime.datetime.now()\n",
    "\n",
    "print(\"Start  : \", dt_start.strftime(\"%Y%m%d-%H%M\"))\n",
    "print(\"End    : \", dt_end.strftime(\"%Y%m%d-%H%M\"))\n",
    "print(\"Elapse : \", dt_end-dt_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b4bc6-043a-48e4-ae2b-b83912f09b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated.\n",
      "250\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "390\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "539\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "302\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "264\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "373\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "259\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "481\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "475\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "450\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "365\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "530\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "429\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "682\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "811\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "257\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "803\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "533\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "339\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "296\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "452\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "867\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  37.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "443\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "309\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "634\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "326\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "636\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "296\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "514\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "894\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  39.0\n",
      "first_0 reward: 22.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "256\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "458\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "534\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "517\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "288\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "343\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "550\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "283\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "588\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "319\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "249\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "336\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "391\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "453\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "408\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "645\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "336\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "298\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "898\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "335\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "476\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "385\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "524\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "528\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "490\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "498\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "317\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "594\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "726\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "302\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "325\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "527\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "740\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "693\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "514\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "1031\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  39.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 22.0\n",
      "Done.\n",
      "terminated.\n",
      "455\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "319\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "338\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "571\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "323\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "323\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "289\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "605\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "288\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "250\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "343\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "476\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "592\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "829\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "457\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "310\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "614\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "239\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "325\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "395\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "472\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "517\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "233\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "401\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "266\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "472\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "245\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "244\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "319\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "288\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "321\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "394\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "364\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "504\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "428\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "677\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "336\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "457\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "357\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "361\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "466\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "644\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "318\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "263\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "595\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "340\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "489\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "314\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "389\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "673\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "565\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "314\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "509\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "271\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "295\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "334\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "588\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "839\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "767\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "483\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "467\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "276\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "778\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "474\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "367\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "267\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "239\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "354\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "903\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  38.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "341\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "264\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "323\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "294\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "274\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "212\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "309\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "465\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "291\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "311\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "481\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "546\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "445\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "427\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "387\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "816\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  37.0\n",
      "first_0 reward: 20.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "475\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "381\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "621\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "341\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "274\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "433\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "422\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "248\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "427\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "314\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "552\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "675\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "394\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "291\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "578\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "629\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "277\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "688\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "317\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "377\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "766\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 22.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "653\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "311\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "248\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "468\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "697\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "300\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "432\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "299\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "350\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "274\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "219\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "256\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "441\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "344\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "649\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "541\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "336\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "663\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "312\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "509\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "417\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "609\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "427\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "489\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "432\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "471\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "493\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "590\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "216\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "216\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  3.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "594\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "385\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "569\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "317\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "295\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "343\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "549\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "275\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "323\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "249\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "298\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "417\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "340\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "531\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "847\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "254\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "540\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "248\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "670\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "587\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "378\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "489\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "489\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "407\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "303\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "865\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  38.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "682\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "425\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "642\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "445\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "371\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "725\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 23.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "363\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "315\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "417\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "523\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "451\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "471\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "456\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "621\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "691\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "939\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 21.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "828\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "708\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "809\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 21.0\n",
      "Done.\n",
      "terminated.\n",
      "528\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "423\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "324\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "240\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "390\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "345\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "567\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "279\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "533\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "414\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "620\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "497\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "387\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "790\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "308\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "634\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "254\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "373\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "415\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "370\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "211\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  3.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "288\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "260\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "306\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "294\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "758\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 20.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "266\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "505\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "663\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "296\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "318\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "363\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "501\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "594\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "416\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "496\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "585\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "496\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "994\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  38.0\n",
      "first_0 reward: 20.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "867\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  37.0\n",
      "first_0 reward: 23.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "390\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "345\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "312\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "296\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "307\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "377\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "269\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "339\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "267\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "425\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "813\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 21.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "302\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "369\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "375\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "344\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "454\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "283\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "677\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "362\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "490\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "562\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "445\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "248\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "426\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "430\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "267\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "324\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "249\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "459\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "521\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "389\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "343\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "377\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "794\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "468\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "319\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "378\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "280\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "535\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "472\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "438\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "521\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "257\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "382\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "344\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "529\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "249\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "423\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "232\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "661\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "388\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "550\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "414\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "615\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "514\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "470\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "254\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "553\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "529\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "329\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "430\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "516\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "653\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "212\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  3.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "594\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "210\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "639\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "688\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "294\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "555\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "774\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "625\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "277\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "390\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "338\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "591\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "487\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "492\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "663\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "721\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "291\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "573\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "350\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "372\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "431\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "318\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2/script-2-play.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Configure the environment\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mspace_invaders_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_action_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb_array\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m channels_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Needed for environments that use images as observations\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channels_last:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Environment processing for image based observations\u001b[39;00m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:17\u001b[0m, in \u001b[0;36mparallel_wrapper_fn.<locals>.par_fn\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpar_fn\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 17\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43menv_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     env \u001b[38;5;241m=\u001b[39m aec_to_parallel_wrapper(env)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/pettingzoo/atari/base_atari_env.py:24\u001b[0m, in \u001b[0;36mbase_env_wrapper_fn.<locals>.env_fn\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menv_fn\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 24\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mraw_env_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     env \u001b[38;5;241m=\u001b[39m wrappers\u001b[38;5;241m.\u001b[39mAssertOutOfBoundsWrapper(env)\n\u001b[1;32m     26\u001b[0m     env \u001b[38;5;241m=\u001b[39m wrappers\u001b[38;5;241m.\u001b[39mOrderEnforcingWrapper(env)\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/pettingzoo/atari/space_invaders/space_invaders.py:109\u001b[0m, in \u001b[0;36mraw_env\u001b[0;34m(alternating_control, moving_shields, zigzaging_bombs, fast_bomb, invisible_invaders, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m version_num \u001b[38;5;241m=\u001b[39m parent_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    108\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m version_num\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseAtariEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspace_invaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_players\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/pettingzoo/atari/base_atari_env.py:33\u001b[0m, in \u001b[0;36mBaseAtariEnv\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBaseAtariEnv\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parallel_to_aec_wrapper(\u001b[43mParallelAtariEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/pettingzoo/atari/base_atari_env.py:114\u001b[0m, in \u001b[0;36mParallelAtariEnv.__init__\u001b[0;34m(self, game, num_players, mode_num, seed, obs_type, full_action_space, env_name, max_cycles, render_mode, auto_rom_install_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrom \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not installed. Please install roms using AutoROM tool (https://github.com/Farama-Foundation/AutoROM) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor specify and double-check the path to your Atari rom using the `rom_path` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrom_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(final)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadROM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrom_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m all_modes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgetAvailableModes(num_players)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_num \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/multi_agent_ale_py/ale_python_interface.py:188\u001b[0m, in \u001b[0;36mALEInterface.loadROM\u001b[0;34m(self, rom_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadROM\u001b[39m(\u001b[38;5;28mself\u001b[39m, rom_file):\n\u001b[0;32m--> 188\u001b[0m     \u001b[43male_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadROM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_str_as_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrom_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "510\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "286\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "426\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "430\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "365\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "562\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "216\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "257\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "474\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "339\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "397\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "483\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "252\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2/script-2-play.py:151\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Save the frame for this step and append to frames list\u001b[39;00m\n\u001b[1;32m    150\u001b[0m frame \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m--> 151\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_label_with_episode_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Take action in environment\u001b[39;00m\n\u001b[1;32m    154\u001b[0m state, reward, termination, truncation, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2/script-2-play.py:25\u001b[0m, in \u001b[0;36m_label_with_episode_number\u001b[0;34m(frame, episode_num)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     text_color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mdrawer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mep: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepisode_num\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_color\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageDraw.py:475\u001b[0m, in \u001b[0;36mImageDraw.text\u001b[0;34m(self, xy, text, fill, font, anchor, spacing, align, direction, features, language, stroke_width, stroke_fill, embedded_color, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m font \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getfont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfont_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiline_check(text):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiline_text(\n\u001b[1;32m    479\u001b[0m         xy,\n\u001b[1;32m    480\u001b[0m         text,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m         embedded_color,\n\u001b[1;32m    492\u001b[0m     )\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageDraw.py:124\u001b[0m, in \u001b[0;36mImageDraw._getfont\u001b[0;34m(self, font_size)\u001b[0m\n\u001b[1;32m    122\u001b[0m     font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mload_default(font_size)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m font\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageDraw.py:115\u001b[0m, in \u001b[0;36mImageDraw.getfont\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# FIXME: should add a font repository\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFont\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageFont.py:901\u001b[0m, in \u001b[0;36mload_default\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"If FreeType support is available, load a version of Aileron Regular,\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    https://dotcolon.net/font/aileron, with a more limited character set.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03m    :return: A font object.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m core\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m         f \u001b[38;5;241m=\u001b[39m \u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb64decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;250;43m                    \u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;43;03mAAEAAAAPAIAAAwBwRkZUTYwDlUAAADFoAAAAHEdERUYAqADnAAAo8AAAACRHUE9ThhmITwAAKfgAA\u001b[39;49;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;43;03mAduR1NVQnHxefoAACkUAAAA4k9TLzJovoHLAAABeAAAAGBjbWFw5lFQMQAAA6gAAAGqZ2FzcP//AA\u001b[39;49;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;43;03mMAACjoAAAACGdseWYmRXoPAAAGQAAAHfhoZWFkE18ayQAAAPwAAAA2aGhlYQboArEAAAE0AAAAJGh\u001b[39;49;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;43;03mtdHjjERZ8AAAB2AAAAdBsb2NhuOexrgAABVQAAADqbWF4cAC7AEYAAAFYAAAAIG5hbWUr+h5lAAAk\u001b[39;49;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;43;03mOAAAA6Jwb3N0D3oPTQAAJ9wAAAEKAAEAAAABGhxJDqIhXw889QALA+gAAAAA0Bqf2QAAAADhCh2h/\u001b[39;49;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;43;03m2r/LgOxAyAAAAAIAAIAAAAAAAAAAQAAA8r/GgAAA7j/av9qA7EAAQAAAAAAAAAAAAAAAAAAAHQAAQ\u001b[39;49;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;43;03mAAAHQAQwAFAAAAAAACAAAAAQABAAAAQAAAAAAAAAADAfoBkAAFAAgCigJYAAAASwKKAlgAAAFeADI\u001b[39;49;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;43;03mBPgAAAAAFAAAAAAAAAAAAAAcAAAAAAAAAAAAAAABVS1dOAEAAIPsCAwL/GgDIA8oA5iAAAJMAAAAA\u001b[39;49;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;43;03mAhICsgAAACAAAwH0AAAAAAAAAU0AAADYAAAA8gA5AVMAVgJEAEYCRAA1AuQAKQKOAEAAsAArATsAZ\u001b[39;49;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;43;03mAE7AB4CMABVAkQAUADc/+EBEgAgANwAJQEv//sCRAApAkQAggJEADwCRAAtAkQAIQJEADkCRAArAk\u001b[39;49;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;43;03mQAMgJEACwCRAAxANwAJQDc/+ECRABnAkQAUAJEAEQB8wAjA1QANgJ/AB0CcwBkArsALwLFAGQCSwB\u001b[39;49;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;43;03mkAjcAZALGAC8C2gBkAQgAZAIgADcCYQBkAj8AZANiAGQCzgBkAuEALwJWAGQC3QAvAmsAZAJJADQC\u001b[39;49;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;43;03mZAAiAqoAXgJuACADuAAaAnEAGQJFABMCTwAuATMAYgEv//sBJwAiAkQAUAH0ADIBLAApAhMAJAJjA\u001b[39;49;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;43;03mEoCEQAeAmcAHgIlAB4BIgAVAmcAHgJRAEoA7gA+AOn/8wIKAEoA9wBGA1cASgJRAEoCSgAeAmMASg\u001b[39;49;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;43;03mJnAB4BSgBKAcsAGAE5ABQCUABCAgIAAQMRAAEB4v/6AgEAAQHOABQBLwBAAPoAYAEvACECRABNA0Y\u001b[39;49;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;43;03mAJAItAHgBKgAcAkQAUAEsAHQAygAgAi0AOQD3ADYA9wAWAaEANgGhABYCbAAlAYMAeAGDADkA6/9q\u001b[39;49;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;43;03mAhsAFAIKABUB/QAVAAAAAwAAAAMAAAAcAAEAAAAAAKQAAwABAAAAHAAEAIgAAAAeABAAAwAOAH4Aq\u001b[39;49;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;43;03mQCrALEAtAC3ALsgGSAdICYgOiBEISL7Av//AAAAIACpAKsAsAC0ALcAuyAYIBwgJiA5IEQhIvsB//\u001b[39;49;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;124;43;03m//4/+5/7j/tP+y/7D/reBR4E/gR+A14CzfTwVxAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;43;03mAAAAAAAEGAAABAAAAAAAAAAECAAAAAgAAAAAAAAAAAAAAAAAAAAEAAAMEBQYHCAkKCwwNDg8QERIT\u001b[39;49;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;43;03mFBUWFxgZGhscHR4fICEiIyQlJicoKSorLC0uLzAxMjM0NTY3ODk6Ozw9Pj9AQUJDREVGR0hJSktMT\u001b[39;49;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;124;43;03mU5PUFFSU1RVVldYWVpbXF1eX2BhAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGQAAA\u001b[39;49;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;43;03mAAAAAAYnFmAAAAAABlAAAAAAAAAAAAAAAAAAAAAAAAAAAAY2htAAAAAAAAAABrbGlqAAAAAHAAbm9\u001b[39;49;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;43;03mycwBnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmACYAJgAmAD4AUgCCAMoBCgFO\u001b[39;49;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;43;03mAVwBcgGIAaYBvAHKAdYB6AH2AgwCIAJKAogCpgLWAw4DIgNkA5wDugPUA+gD/AQQBEYEogS8BPoFJ\u001b[39;49;00m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;43;03mgVSBWoFgAWwBcoF1gX6BhQGJAZMBmgGiga0BuIHGgdUB2YHkAeiB8AH3AfyCAoIHAgqCDoITghcCG\u001b[39;49;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;43;03moIogjSCPoJKglYCXwJwgnqCgIKKApACl4Klgq8CtwLDAs8C1YLjAuyC9oL7gwMDCYMSAxgDKAMrAz\u001b[39;49;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;43;03mqDQoNTA1mDYQNoA2uDcAN2g3oDfYODA4iDkoOXA5sDnoOnA7EDvwAAAAFAAAAAAH0ArwAAwAGAAkA\u001b[39;49;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;43;03mDAAPAAAxESERAxMhExcRASELARETAfT6qv6syKr+jgFUqsiqArz9RAGLAP/+1P8B/v3VAP8BLP4CA\u001b[39;49;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;43;03mP8AAgA5//IAuQKyAAMACwAANyMDMwIyFhQGIiY0oE4MZk84JCQ4JLQB/v3AJDgkJDgAAgBWAeUBPA\u001b[39;49;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;43;03mLfAAMABwAAEyMnMxcjJzOmRgpagkYKWgHl+vr6AAAAAAIARgAAAf4CsgAbAB8AAAEHMxUjByM3Iwc\u001b[39;49;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;43;03mjNyM1MzcjNTM3MwczNzMHMxUrAQczAZgdZXEvOi9bLzovWmYdZXEvOi9bLzovWp9bHlsBn4w429vb\u001b[39;49;00m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;43;03m2ziMONvb29s4jAAAAAMANf+mAg4DDAAfACYALAAAJRQGBxUjNS4BJzMeARcRLgE0Njc1MxUeARcjJ\u001b[39;49;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;43;03micVHgEBFBYXNQ4BExU+ATU0Ag5xWDpgcgRcBz41Xl9oVTpVYwpcC1ttXP6cLTQuM5szOrVRZwlOTQ\u001b[39;49;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;43;03mZqVzZECAEAGlukZAlOTQdrUG8O7iNlAQgxNhDlCDj+8/YGOjReAAAAAAUAKf/yArsCvAAHAAsAFQA\u001b[39;49;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;43;03mdACcAABIyFhQGIiY0EyMBMwQiBhUUFjI2NTQSMhYUBiImNDYiBhUUFjI2NTR5iFBQiFCVVwHAV/5c\u001b[39;49;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;124;43;03mOiMjOiPmiFBQiFCxOiMjOiMCvFaSVlaS/ZoCsjIzMC80NC8w/uNWklZWkhozMC80NC8wAAAAAgBA/\u001b[39;49;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;43;03m/ICbgLAACIALgAAARUjEQYjIiY1NDY3LgE1NDYzMhcVJiMiBhUUFhcWOwE1MxUFFBYzMjc1IyIHDg\u001b[39;49;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;43;03mECbmBcYYOOVkg7R4hsQjY4Q0RNRD4SLDxW/pJUXzksPCkUUk0BgUb+zBVUZ0BkDw5RO1huCkULQzp\u001b[39;49;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;43;03mCOAMBcHDHRz0J/AIHRQAAAAEAKwHlAIUC3wADAAATIycze0YKWgHl+gAAAAABAGT/sAEXAwwACQAA\u001b[39;49;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;43;03mEzMGEBcjLgE0Nt06dXU6OUBAAwzG/jDGVePs4wAAAAEAHv+wANEDDAAJAAATMx4BFAYHIzYQHjo5Q\u001b[39;49;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;43;03mEA5OnUDDFXj7ONVxgHQAAAAAQBVAFIB2wHbAA4AAAE3FwcXBycHJzcnNxcnMwEtmxOfcTJjYzJxnx\u001b[39;49;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;43;03mObCj4BKD07KYolmZkliik7PbMAAQBQAFUB9AIlAAsAAAEjFSM1IzUzNTMVMwH0tTq1tTq1AR/Kyjj\u001b[39;49;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;124;43;03mOzgAAAAAB/+H/iACMAGQABAAANwcjNzOMWlFOXVrS3AAAAQAgAP8A8gE3AAMAABMjNTPy0tIA/zgA\u001b[39;49;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;124;43;03mAQAl//IApQByAAcAADYyFhQGIiY0STgkJDgkciQ4JCQ4AAAAAf/7/+IBNALQAAMAABcjEzM5Pvs+H\u001b[39;49;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;43;03mgLuAAAAAAIAKf/yAhsCwAADAAcAABIgECA2IBAgKQHy/g5gATL+zgLA/TJEAkYAAAAAAQCCAAABlg\u001b[39;49;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;43;03mKyAAgAAAERIxEHNTc2MwGWVr6SIygCsv1OAldxW1sWAAEAPAAAAg4CwAAZAAA3IRUhNRM+ATU0JiM\u001b[39;49;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;124;43;03miDwEjNz4BMzIWFRQGB7kBUv4x+kI2QTt+EAFWAQp8aGVtSl5GRjEA/0RVLzlLmAoKa3FsUkNxXQAA\u001b[39;49;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;43;03mAAEALf/yAhYCwAAqAAABHgEVFAYjIi8BMxceATMyNjU0KwE1MzI2NTQmIyIGDwEjNz4BMzIWFRQGA\u001b[39;49;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;43;03mYxBSZJo2RUBVgEHV0JBUaQREUBUQzc5TQcBVgEKfGhfcEMBbxJbQl1x0AoKRkZHPn9GSD80QUVCCg\u001b[39;49;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;124;43;03mpfbGBPOlgAAAACACEAAAIkArIACgAPAAAlIxUjNSE1ATMRMyMRBg8BAiRXVv6qAVZWV60dHLCurq4\u001b[39;49;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;43;03mrAdn+QgFLMibzAAABADn/8gIZArIAHQAAATIWFRQGIyIvATMXFjMyNjU0JiMiByMTIRUhBzc2ATNv\u001b[39;49;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;43;03md5Fl1RQBVgIad0VSTkVhL1IwAYj+vh8rMAHHgGdtgcUKCoFXTU5bYgGRRvAuHQAAAAACACv/8gITA\u001b[39;49;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;43;03msAAFwAjAAABMhYVFAYjIhE0NjMyFh8BIycmIyIDNzYTMjY1NCYjIgYVFBYBLmp7imr0l3RZdAgBXA\u001b[39;49;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;43;03mIYZ5wKJzU6QVNJSz5SUAHSgWltiQFGxcNlVQoKdv7sPiz+ZF1LTmJbU0lhAAAAAQAyAAACGgKyAAY\u001b[39;49;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;43;03mAAAEVASMBITUCGv6oXAFL/oECsij9dgJsRgAAAAMALP/xAhgCwAAWACAALAAAAR4BFRQGIyImNTQ2\u001b[39;49;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;43;03mNy4BNTQ2MhYVFAYmIgYVFBYyNjU0AzI2NTQmIyIGFRQWAZQ5S5BmbIpPOjA7ecp5P2F8Q0J8RIVJS\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;43;03m0pLTEtOAW0TXTxpZ2ZqPF0SE1A3VWVlVTdQ/UU0N0RENzT9/ko+Ok1NOj1LAAIAMf/yAhkCwAAXAC\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;43;03mMAAAEyERQGIyImLwEzFxYzMhMHBiMiJjU0NhMyNjU0JiMiBhUUFgEl9Jd0WXQIAVwCGGecCic1SWp\u001b[39;49;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;43;03m7imo+UlBAQVNJAsD+usXDZVUKCnYBFD4sgWltif5kW1NJYV1LTmIAAAACACX/8gClAiAABwAPAAAS\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;43;03mMhYUBiImNBIyFhQGIiY0STgkJDgkJDgkJDgkAiAkOCQkOP52JDgkJDgAAAAC/+H/iAClAiAABwAMA\u001b[39;49;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;43;03mAASMhYUBiImNBMHIzczSTgkJDgkaFpSTl4CICQ4JCQ4/mba5gAAAQBnAB4B+AH0AAYAAAENARUlNS\u001b[39;49;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;43;03mUB+P6qAVb+bwGRAbCmpkbJRMkAAAIAUAC7AfQBuwADAAcAAAEhNSERITUhAfT+XAGk/lwBpAGDOP8\u001b[39;49;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;43;03mAOAABAEQAHgHVAfQABgAAARUFNS0BNQHV/m8BVv6qAStEyUSmpkYAAAAAAgAj//IB1ALAABgAIAAA\u001b[39;49;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;124;43;03mATIWFRQHDgEHIz4BNz4BNTQmIyIGByM+ARIyFhQGIiY0AQRibmktIAJWBSEqNig+NTlHBFoDezQ4J\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;43;03mCQ4JALAZ1BjaS03JS1DMD5LLDQ/SUVgcv2yJDgkJDgAAAAAAgA2/5gDFgKYADYAQgAAAQMGFRQzMj\u001b[39;49;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;43;03mY1NCYjIg4CFRQWMzI2NxcGIyImNTQ+AjMyFhUUBiMiJwcGIyImNTQ2MzIfATcHNzYmIyIGFRQzMjY\u001b[39;49;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;43;03mCej8EJjJJlnBAfGQ+oHtAhjUYg5OPx0h2k06Os3xRWQsVLjY5VHtdPBwJETcJDyUoOkZEJz8B0f74\u001b[39;49;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;43;03mEQ8kZl6EkTFZjVOLlyknMVm1pmCiaTq4lX6CSCknTVRmmR8wPdYnQzxuSWVGAAIAHQAAAncCsgAHA\u001b[39;49;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;43;03mAoAACUjByMTMxMjATMDAcj+UVz4dO5d/sjPZPT0ArL9TgE6ATQAAAADAGQAAAJMArIAEAAbACcAAA\u001b[39;49;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;43;03mEeARUUBgcGKwERMzIXFhUUJRUzMjc2NTQnJiMTPgE1NCcmKwEVMzIBvkdHZkwiNt7LOSGq/oeFHBt\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;124;43;03mhahIlSTM+cB8Yj5UWAW8QT0VYYgwFArIEF5Fv1eMED2NfDAL93AU+N24PBP0AAAAAAQAv//ICjwLA\u001b[39;49;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;124;43;03mABsAAAEyFh8BIycmIyIGFRQWMzI/ATMHDgEjIiY1NDYBdX+PCwFWAiKiaHx5ZaIiAlYBCpWBk6a0A\u001b[39;49;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;124;43;03msCAagoKpqN/gaOmCgplhcicn8sAAAIAZAAAAp8CsgAMABkAAAEeARUUBgcGKwERMzITPgE1NCYnJi\u001b[39;49;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;124;43;03msBETMyAY59lJp8IzXN0jUVWmdjWRs5d3I4Aq4QqJWUug8EArL9mQ+PeHGHDgX92gAAAAABAGQAAAI\u001b[39;49;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;124;43;03mvArIACwAAJRUhESEVIRUhFSEVAi/+NQHB/pUBTf6zRkYCskbwRvAAAAABAGQAAAIlArIACQAAExUh\u001b[39;49;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;124;43;03mFSERIxEhFboBQ/69VgHBAmzwRv7KArJGAAAAAAEAL//yAo8CwAAfAAABMxEjNQcGIyImNTQ2MzIWH\u001b[39;49;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;43;03mwEjJyYjIgYVFBYzMjY1IwGP90wfPnWTprSSf48LAVYCIqJofHllVG+hAU3+s3hARsicn8uAagoKpq\u001b[39;49;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;124;43;03mN/gaN1XAAAAAEAZAAAAowCsgALAAABESMRIREjETMRIRECjFb+hFZWAXwCsv1OAS7+0gKy/sQBPAA\u001b[39;49;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;124;43;03mAAAABAGQAAAC6ArIAAwAAMyMRM7pWVgKyAAABADf/8gHoArIAEwAAAREUBw4BIyImLwEzFxYzMjc2\u001b[39;49;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;43;03mNREB6AIFcGpgbQIBVgIHfXQKAQKy/lYxIltob2EpKYyEFD0BpwAAAAABAGQAAAJ0ArIACwAACQEjA\u001b[39;49;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;43;03mwcVIxEzEQEzATsBJ3ntQlZWAVVlAWH+nwEnR+ACsv6RAW8AAQBkAAACLwKyAAUAACUVIREzEQIv/j\u001b[39;49;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;43;03mVWRkYCsv2UAAABAGQAAAMUArIAFAAAAREjETQ3BgcDIwMmJxYVESMRMxsBAxRWAiMxemx8NxsCVo7\u001b[39;49;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;43;03mMywKy/U4BY7ZLco7+nAFmoFxLtP6dArL9lwJpAAAAAAEAZAAAAoACsgANAAAhIwEWFREjETMBJjUR\u001b[39;49;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;124;43;03mMwKAhP67A1aEAUUDVAJeeov+pwKy/aJ5jAFZAAAAAgAv//ICuwLAAAkAEwAAEiAWFRQGICY1NBIyN\u001b[39;49;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;43;03mjU0JiIGFRTbATSsrP7MrNrYenrYegLAxaKhxsahov47nIeIm5uIhwACAGQAAAJHArIADgAYAAABHg\u001b[39;49;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;43;03mEVFAYHBisBESMRMzITNjQnJisBETMyAZRUX2VOHzuAVtY7GlxcGDWIiDUCrgtnVlVpCgT+5gKy/rU\u001b[39;49;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;43;03mV1BUF/vgAAAACAC//zAK9AsAAEgAcAAAlFhcHJiMiBwYjIiY1NDYgFhUUJRQWMjY1NCYiBgI9PUMx\u001b[39;49;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;43;03mUDcfKh8omqysATSs/dR62Hp62HpICTg7NgkHxqGixcWitbWHnJyHiJubAAIAZAAAAlgCsgAXACMAA\u001b[39;49;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;43;03mCUWFyMmJyYnJisBESMRMzIXHgEVFAYHFiUzMjc+ATU0JyYrAQIqDCJfGQwNWhAhglbiOx9QXEY1Tv\u001b[39;49;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;43;03m6bhDATMj1lGSyMtYgtOXR0BwH+1wKyBApbU0BSESRAAgVAOGoQBAABADT/8gIoAsAAJQAAATIWFyM\u001b[39;49;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;43;03muASMiBhUUFhceARUUBiMiJiczHgEzMjY1NCYnLgE1NDYBOmd2ClwGS0E6SUNRdW+HZnKKC1wPWkQ9\u001b[39;49;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;43;03mUk1cZGuEAsBwXUJHNjQ3OhIbZVZZbm5kREo+NT5DFRdYUFdrAAAAAAEAIgAAAmQCsgAHAAABIxEjE\u001b[39;49;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;43;03mSM1IQJk9lb2AkICbP2UAmxGAAEAXv/yAmQCsgAXAAABERQHDgEiJicmNREzERQXHgEyNjc2NRECZA\u001b[39;49;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;43;03mIIgfCBCAJWAgZYmlgGAgKy/k0qFFxzc1wUKgGz/lUrEkRQUEQSKwGrAAAAAAEAIAAAAnoCsgAGAAA\u001b[39;49;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;43;03mhIwMzGwEzAYJ07l3N1FwCsv2PAnEAAAEAGgAAA7ECsgAMAAABAyMLASMDMxsBMxsBA7HAcZyicrZi\u001b[39;49;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;43;03mkaB0nJkCsv1OAlP9rQKy/ZsCW/2kAmYAAAEAGQAAAm8CsgALAAAhCwEjEwMzGwEzAxMCCsrEY/bkY\u001b[39;49;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;124;43;03mre+Y/D6AST+3AFcAVb+5gEa/q3+oQAAAQATAAACUQKyAAgAAAERIxEDMxsBMwFdVvRjwLphARD+8A\u001b[39;49;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;43;03mEQAaL+sQFPAAABAC4AAAI5ArIACQAAJRUhNQEhNSEVAQI5/fUBof57Aen+YUZGQgIqRkX92QAAAAA\u001b[39;49;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;124;43;03mBAGL/sAEFAwwABwAAARUjETMVIxEBBWlpowMMOP0UOANcAAAB//v/4gE0AtAAAwAABSMDMwE0Pvs+\u001b[39;49;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;124;43;03mHgLuAAAAAQAi/7AAxQMMAAcAABcjNTMRIzUzxaNpaaNQOALsOAABAFAA1wH0AmgABgAAJQsBIxMzE\u001b[39;49;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;43;03mwGwjY1GsESw1wFZ/qcBkf5vAAAAAQAy/6oBwv/iAAMAAAUhNSEBwv5wAZBWOAAAAAEAKQJEALYCsg\u001b[39;49;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;43;03mADAAATIycztjhVUAJEbgAAAAACACT/8gHQAiAAHQAlAAAhJwcGIyImNTQ2OwE1NCcmIyIHIz4BMzI\u001b[39;49;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;43;03mXFh0BFBcnMjY9ASYVFAF6CR0wVUtgkJoiAgdgaQlaBm1Zrg4DCuQ9R+5MOSFQR1tbDiwUUXBUXowf\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;43;03mJ8c9SjRORzYSgVwAAAAAAgBK//ICRQLfABEAHgAAATIWFRQGIyImLwEVIxEzETc2EzI2NTQmIyIGH\u001b[39;49;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;43;03mQEUFgFUcYCVbiNJEyNWVigySElcU01JXmECIJd4i5QTEDRJAt/+3jkq/hRuZV55ZWsdX14AAQAe//\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;43;03mIB9wIgABgAAAEyFhcjJiMiBhUUFjMyNjczDgEjIiY1NDYBF152DFocbEJXU0A1Rw1aE3pbaoKQAiB\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;43;03moWH5qZm1tPDlaXYuLgZcAAAACAB7/8gIZAt8AEQAeAAABESM1BwYjIiY1NDYzMhYfAREDMjY9ATQm\u001b[39;49;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;43;03mIyIGFRQWAhlWKDJacYCVbiNJEyOnSV5hQUlcUwLf/SFVOSqXeIuUExA0ARb9VWVrHV9ebmVeeQACA\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;43;03mB7/8gH9AiAAFQAbAAABFAchHgEzMjY3Mw4BIyImNTQ2MzIWJyIGByEmAf0C/oAGUkA1SwlaD4FXbI\u001b[39;49;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;43;03mWObmt45UBVBwEqDQEYFhNjWD84W16Oh3+akU9aU60AAAEAFQAAARoC8gAWAAATBh0BMxUjESMRIzU\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;43;03mzNTQ3PgEzMhcVJqcDbW1WOTkDB0k8Hx5oAngVITRC/jQBzEIsJRs5PwVHEwAAAAIAHv8uAhkCIAAi\u001b[39;49;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;43;03mAC8AAAERFAcOASMiLwEzFx4BMzI2NzY9AQcGIyImNTQ2MzIWHwE1AzI2PQE0JiMiBhUUFgIZAQSEd\u001b[39;49;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;43;03mNwRAVcBBU5DTlUDASgyWnGAlW4jSRMjp0leYUFJXFMCEv5wSh1zeq8KCTI8VU0ZIQk5Kpd4i5QTED\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;43;03mRJ/iJlax1fXm5lXnkAAQBKAAACCgLkABcAAAEWFREjETQnLgEHDgEdASMRMxE3NjMyFgIIAlYCBDs\u001b[39;49;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;43;03m6RVRWViE5UVViAYUbQP7WASQxGzI7AQJyf+kC5P7TPSxUAAACAD4AAACsAsAABwALAAASMhYUBiIm\u001b[39;49;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;43;03mNBMjETNeLiAgLiBiVlYCwCAuICAu/WACEgAC//P/LgCnAsAABwAVAAASMhYUBiImNBcRFAcGIyInN\u001b[39;49;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;43;03mRY3NjURWS4gIC4gYgMLcRwNSgYCAsAgLiAgLo79wCUbZAJGBzMOHgJEAAAAAQBKAAACCALfAAsAAC\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;43;03mEnBxUjETMREzMHEwGTwTJWVvdu9/rgN6kC3/4oAQv6/ugAAQBG//wA3gLfAA8AABMRFBceATcVBiM\u001b[39;49;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;43;03miJicmNRGcAQIcIxkkKi4CAQLf/bkhERoSBD4EJC8SNAJKAAAAAQBKAAADEAIgACQAAAEWFREjETQn\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;43;03mJiMiFREjETQnJiMiFREjETMVNzYzMhYXNzYzMhYDCwVWBAxedFYEDF50VlYiJko7ThAvJkpEVAGfI\u001b[39;49;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;43;03mjn+vAEcQyRZ1v76ARxDJFnW/voCEk08HzYtRB9HAAAAAAEASgAAAgoCIAAWAAABFhURIxE0JyYjIg\u001b[39;49;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;43;03mYdASMRMxU3NjMyFgIIAlYCCXBEVVZWITlRVWIBhRtA/tYBJDEbbHR/6QISWz0sVAAAAAACAB7/8gI\u001b[39;49;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;43;03msAiAABwARAAASIBYUBiAmNBIyNjU0JiIGFRSlAQCHh/8Ah7ieWlqeWgIgn/Cfn/D+s3ZfYHV1YF8A\u001b[39;49;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;43;03mAgBK/zwCRQIgABEAHgAAATIWFRQGIyImLwERIxEzFTc2EzI2NTQmIyIGHQEUFgFUcYCVbiNJEyNWV\u001b[39;49;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;43;03migySElcU01JXmECIJd4i5QTEDT+8wLWVTkq/hRuZV55ZWsdX14AAgAe/zwCGQIgABEAHgAAAREjEQ\u001b[39;49;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;43;03mcGIyImNTQ2MzIWHwE1AzI2PQE0JiMiBhUUFgIZVigyWnGAlW4jSRMjp0leYUFJXFMCEv0qARk5Kpd\u001b[39;49;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;43;03m4i5QTEDRJ/iJlax1fXm5lXnkAAQBKAAABPgIeAA0AAAEyFxUmBhURIxEzFTc2ARoWDkdXVlYwIwIe\u001b[39;49;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;43;03mB0EFVlf+0gISU0cYAAEAGP/yAa0CIAAjAAATMhYXIyYjIgYVFBYXHgEVFAYjIiYnMxYzMjY1NCYnL\u001b[39;49;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;43;03mgE1NDbkV2MJWhNdKy04PF1XbVhWbgxaE2ktOjlEUllkAiBaS2MrJCUoEBlPQkhOVFZoKCUmLhIWSE\u001b[39;49;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;43;03mBIUwAAAAEAFP/4ARQCiQAXAAATERQXHgE3FQYjIiYnJjURIzUzNTMVMxWxAQMmMx8qMjMEAUdHVmM\u001b[39;49;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;43;03mBzP7PGw4mFgY/BSwxDjQBNUJ7e0IAAAABAEL/8gICAhIAFwAAAREjNQcGIyImJyY1ETMRFBceATMy\u001b[39;49;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;43;03mNj0BAgJWITlRT2EKBVYEBkA1RFECEv3uWj4qTToiOQE+/tIlJC43c4DpAAAAAAEAAQAAAfwCEgAGA\u001b[39;49;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;43;03mAABAyMDMxsBAfzJaclfop8CEv3uAhL+LQHTAAABAAEAAAMLAhIADAAAAQMjCwEjAzMbATMbAQMLqW\u001b[39;49;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;43;03mZ2dmapY3t0a3Z7AhL97gG+/kICEv5AAcD+QwG9AAAB//oAAAHWAhIACwAAARMjJwcjEwMzFzczARq\u001b[39;49;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;43;03m8ZIuKY763ZoWFYwEO/vLV1QEMAQbNzQAAAQAB/y4B+wISABEAAAEDDgEjIic1FjMyNj8BAzMbAQH7\u001b[39;49;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;43;03m2iFZQB8NDRIpNhQH02GenQIS/cFVUAJGASozEwIt/i4B0gABABQAAAGxAg4ACQAAJRUhNQEhNSEVA\u001b[39;49;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;43;03mQGx/mMBNP7iAYL+zkREQgGIREX+ewAAAAABAED/sAEOAwwALAAAASMiBhUUFxYVFAYHHgEVFAcGFR\u001b[39;49;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;43;03mQWOwEVIyImNTQ3NjU0JzU2NTQnJjU0NjsBAQ4MKiMLDS4pKS4NCyMqDAtERAwLUlILDERECwLUGBk\u001b[39;49;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;43;03mWTlsgKzUFBTcrIFtOFhkYOC87GFVMIkUIOAhFIkxVGDsvAAAAAAEAYP84AJoDIAADAAAXIxEzmjo6\u001b[39;49;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;124;43;03myAPoAAEAIf+wAO8DDAAsAAATFQYVFBcWFRQGKwE1MzI2NTQnJjU0NjcuATU0NzY1NCYrATUzMhYVF\u001b[39;49;00m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;124;43;03mAcGFRTvUgsMREQLDCojCw0uKSkuDQsjKgwLREQMCwF6OAhFIkxVGDsvOBgZFk5bICs1BQU3KyBbTh\u001b[39;49;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;124;43;03mYZGDgvOxhVTCJFAAABAE0A3wH2AWQAEwAAATMUIyImJyYjIhUjNDMyFhcWMzIBvjhuGywtQR0xOG4\u001b[39;49;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;43;03mbLC1BHTEBZIURGCNMhREYIwAAAwAk/94DIgLoAAcAEQApAAAAIBYQBiAmECQgBhUUFiA2NTQlMhYX\u001b[39;49;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;43;03mIyYjIgYUFjMyNjczDgEjIiY1NDYBAQFE3d3+vN0CB/7wubkBELn+xVBnD1wSWDo+QTcqOQZcEmZWX\u001b[39;49;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;43;03mHN2Aujg/rbg4AFKpr+Mjb6+jYxbWEldV5ZZNShLVn5na34AAgB4AFIB9AGeAAUACwAAAQcXIyc3Mw\u001b[39;49;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;43;03mcXIyc3AUqJiUmJifOJiUmJiQGepqampqampqYAAAIAHAHSAQ4CwAAHAA8AABIyFhQGIiY0NiIGFBY\u001b[39;49;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;43;03myNjRgakREakSTNCEhNCECwEJqQkJqCiM4IyM4AAAAAAIAUAAAAfQCCwALAA8AAAEzFSMVIzUjNTM1\u001b[39;49;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;43;03mMxMhNSEBP7W1OrW1OrX+XAGkAVs4tLQ4sP31OAAAAQB0AkQBAQKyAAMAABMjNzOsOD1QAkRuAAAAA\u001b[39;49;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;43;03mAEAIADsAKoBdgAHAAASMhYUBiImNEg6KCg6KAF2KDooKDoAAAIAOQBSAbUBngAFAAsAACUHIzcnMw\u001b[39;49;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;43;03mUHIzcnMwELiUmJiUkBM4lJiYlJ+KampqampqYAAAABADYB5QDhAt8ABAAAEzczByM2Xk1OXQHv8Po\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;43;03mAAQAWAeUAwQLfAAQAABMHIzczwV5NTl0C1fD6AAIANgHlAYsC3wAEAAkAABM3MwcjPwEzByM2Xk1O\u001b[39;49;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;43;03mXapeTU5dAe/w+grw+gAAAgAWAeUBawLfAAQACQAAEwcjNzMXByM3M8FeTU5dql5NTl0C1fD6CvD6A\u001b[39;49;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;43;03mAADACX/8gI1AHIABwAPABcAADYyFhQGIiY0NjIWFAYiJjQ2MhYUBiImNEk4JCQ4JOw4JCQ4JOw4JC\u001b[39;49;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;43;03mQ4JHIkOCQkOCQkOCQkOCQkOCQkOAAAAAEAeABSAUoBngAFAAABBxcjJzcBSomJSYmJAZ6mpqamAAA\u001b[39;49;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;43;03mAAAEAOQBSAQsBngAFAAAlByM3JzMBC4lJiYlJ+KampgAAAf9qAAABgQKyAAMAACsBATM/VwHAVwKy\u001b[39;49;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;43;03mAAAAAAIAFAHIAdwClAAHABQAABMVIxUjNSM1BRUjNwcjJxcjNTMXN9pKMkoByDICKzQqATJLKysCl\u001b[39;49;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;43;03mCmjoykBy46KiY3Lm5sAAQAVAAABvALyABgAAAERIxEjESMRIzUzNTQ3NjMyFxUmBgcGHQEBvFbCVj\u001b[39;49;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;43;03mk5AxHHHx5iVgcDAg798gHM/jQBzEIOJRuWBUcIJDAVIRYAAAABABX//AHkAvIAJQAAJR4BNxUGIyI\u001b[39;49;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;43;03mmJyY1ESYjIgcGHQEzFSMRIxEjNTM1NDc2MzIXERQBowIcIxkkKi4CAR4nXgwDbW1WLy8DEbNdOmYa\u001b[39;49;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;124;43;03mEQQ/BCQvEjQCFQZWFSEWQv40AcxCDiUblhP9uSEAAAAAAAAWAQ4AAQAAAAAAAAATACgAAQAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;43;03mQAHAEwAAQAAAAAAAgAHAGQAAQAAAAAAAwAaAKIAAQAAAAAABAAHAM0AAQAAAAAABQA8AU8AAQAAAA\u001b[39;49;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;43;03mAABgAPAawAAQAAAAAACAALAdQAAQAAAAAACQALAfgAAQAAAAAACwAXAjQAAQAAAAAADAAXAnwAAwA\u001b[39;49;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;43;03mBBAkAAAAmAAAAAwABBAkAAQAOADwAAwABBAkAAgAOAFQAAwABBAkAAwA0AGwAAwABBAkABAAOAL0A\u001b[39;49;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;43;03mAwABBAkABQB4ANUAAwABBAkABgAeAYwAAwABBAkACAAWAbwAAwABBAkACQAWAeAAAwABBAkACwAuA\u001b[39;49;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;43;03mgQAAwABBAkADAAuAkwATgBvACAAUgBpAGcAaAB0AHMAIABSAGUAcwBlAHIAdgBlAGQALgAATm8gUm\u001b[39;49;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;43;03mlnaHRzIFJlc2VydmVkLgAAQQBpAGwAZQByAG8AbgAAQWlsZXJvbgAAUgBlAGcAdQBsAGEAcgAAUmV\u001b[39;49;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;43;03mndWxhcgAAMQAuADEAMAAyADsAVQBLAFcATgA7AEEAaQBsAGUAcgBvAG4ALQBSAGUAZwB1AGwAYQBy\u001b[39;49;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;43;03mAAAxLjEwMjtVS1dOO0FpbGVyb24tUmVndWxhcgAAQQBpAGwAZQByAG8AbgAAQWlsZXJvbgAAVgBlA\u001b[39;49;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;43;03mHIAcwBpAG8AbgAgADEALgAxADAAMgA7AFAAUwAgADAAMAAxAC4AMQAwADIAOwBoAG8AdABjAG8Abg\u001b[39;49;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;43;03mB2ACAAMQAuADAALgA3ADAAOwBtAGEAawBlAG8AdABmAC4AbABpAGIAMgAuADUALgA1ADgAMwAyADk\u001b[39;49;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;43;03mAAFZlcnNpb24gMS4xMDI7UFMgMDAxLjEwMjtob3Rjb252IDEuMC43MDttYWtlb3RmLmxpYjIuNS41\u001b[39;49;00m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;43;03mODMyOQAAQQBpAGwAZQByAG8AbgAtAFIAZQBnAHUAbABhAHIAAEFpbGVyb24tUmVndWxhcgAAUwBvA\u001b[39;49;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;43;03mHIAYQAgAFMAYQBnAGEAbgBvAABTb3JhIFNhZ2FubwAAUwBvAHIAYQAgAFMAYQBnAGEAbgBvAABTb3\u001b[39;49;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124;43;03mJhIFNhZ2FubwAAaAB0AHQAcAA6AC8ALwB3AHcAdwAuAGQAbwB0AGMAbwBsAG8AbgAuAG4AZQB0AAB\u001b[39;49;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;43;03modHRwOi8vd3d3LmRvdGNvbG9uLm5ldAAAaAB0AHQAcAA6AC8ALwB3AHcAdwAuAGQAbwB0AGMAbwBs\u001b[39;49;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;43;03mAG8AbgAuAG4AZQB0AABodHRwOi8vd3d3LmRvdGNvbG9uLm5ldAAAAAACAAAAAAAA/4MAMgAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAHQAAAABAAIAAwAEAAUABgAHAAgACQAKAAsADAANAA4ADwAQABEAEgATAB\u001b[39;49;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;43;03mQAFQAWABcAGAAZABoAGwAcAB0AHgAfACAAIQAiACMAJAAlACYAJwAoACkAKgArACwALQAuAC8AMAA\u001b[39;49;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;43;03mxADIAMwA0ADUANgA3ADgAOQA6ADsAPAA9AD4APwBAAEEAQgBDAEQARQBGAEcASABJAEoASwBMAE0A\u001b[39;49;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;43;03mTgBPAFAAUQBSAFMAVABVAFYAVwBYAFkAWgBbAFwAXQBeAF8AYABhAIsAqQCDAJMAjQDDAKoAtgC3A\u001b[39;49;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;43;03mLQAtQCrAL4AvwC8AIwAwADBAAAAAAAB//8AAgABAAAADAAAABwAAAACAAIAAwBxAAEAcgBzAAIABA\u001b[39;49;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;43;03mAAAAIAAAABAAAACgBMAGYAAkRGTFQADmxhdG4AGgAEAAAAAP//AAEAAAAWAANDQVQgAB5NT0wgABZ\u001b[39;49;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;43;03mST00gABYAAP//AAEAAAAA//8AAgAAAAEAAmxpZ2EADmxvY2wAFAAAAAEAAQAAAAEAAAACAAYAEAAG\u001b[39;49;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;124;43;03mAAAAAgASADQABAAAAAEATAADAAAAAgAQABYAAQAcAAAAAQABAE8AAQABAGcAAQABAE8AAwAAAAIAE\u001b[39;49;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;43;03mAAWAAEAHAAAAAEAAQAvAAEAAQBnAAEAAQAvAAEAGgABAAgAAgAGAAwAcwACAE8AcgACAEwAAQABAE\u001b[39;49;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;43;03mkAAAABAAAACgBGAGAAAkRGTFQADmxhdG4AHAAEAAAAAP//AAIAAAABABYAA0NBVCAAFk1PTCAAFlJ\u001b[39;49;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;43;03mPTSAAFgAA//8AAgAAAAEAAmNwc3AADmtlcm4AFAAAAAEAAAAAAAEAAQACAAYADgABAAAAAQASAAIA\u001b[39;49;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;43;03mAAACAB4ANgABAAoABQAFAAoAAgABACQAPQAAAAEAEgAEAAAAAQAMAAEAOP/nAAEAAQAkAAIGigAEA\u001b[39;49;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;43;03mAAFJAXKABoAGQAA//gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;124;43;03mAAAAD/sv+4/+z/7v/MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;124;43;03mAAAAAAAD/xAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/9T/6AAAAAD/8QAA\u001b[39;49;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;43;03mABD/vQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/7gAAAAAAAAAAAAAAAAAA//MAA\u001b[39;49;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABIAAAAAAAAAAP/5AAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/gAAD/4AAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//L/9AAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAA/+gAAAAAAAkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/zAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/mAAAAAAAAAAAAAAAAAAD\u001b[39;49;00m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;124;43;03m/4gAA//AAAAAA//YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/+AAAAAAAAP/OAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/zv/qAAAAAP/0AAAACAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/ZAAD/egAA/1kAAAAA/5D/rgAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAD/9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAD/8AAA/7b/8P+wAAD/8P/E/98AAAAA/8P/+P/0//oAAAAAAAAAAAAA//gA\u001b[39;49;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/+AAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/w//C/9MAAP/SAAD/9wAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/yAAA/+kAAAAA//QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/9wAAAAD//QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAP/2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAP/cAAAAAAAAAAAAAAAA/7YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAP/8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/6AAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAkAFAAEAAAAAQACwAAABcA\u001b[39;49;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;124;43;03mBgAAAAAAAAAIAA4AAAAAAAsAEgAAAAAAAAATABkAAwANAAAAAQAJAAAAAAAAAAAAAAAAAAAAGAAAA\u001b[39;49;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;124;43;03mAAABwAAAAAAAAAAAAAAFQAFAAAAAAAYABgAAAAUAAAACgAAAAwAAgAPABEAFgAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFAAEAEQBdAAYAAAAAAAAAAAAAAAAAAAAAAAA\u001b[39;49;00m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;43;03mAAAAAAAAAAAAAAAAAAAAAAAAAAQAAAAcAAAAAAAAABwAAAAAACAAAAAAAAAAAAAcAAAAHAAAAEwAJ\u001b[39;49;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;43;03mABUADgAPAAAACwAQAAAAAAAAAAAAAAAAAAUAGAACAAIAAgAAAAIAGAAXAAAAGAAAABYAFgACABYAA\u001b[39;49;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;43;03mgAWAAAAEQADAAoAFAAMAA0ABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAASAAAAEgAGAAEAHgAkAC\u001b[39;49;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;43;03mYAJwApACoALQAuAC8AMgAzADcAOAA5ADoAPAA9AEUASABOAE8AUgBTAFUAVwBZAFoAWwBcAF0AcwA\u001b[39;49;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;43;03mAAAAAAQAAAADa3tfFAAAAANAan9kAAAAA4QodoQ==\u001b[39;49;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m   1126\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         f \u001b[38;5;241m=\u001b[39m ImageFont()\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageFont.py:819\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageFont.py:816\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageFont.py:249\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mgetfont(\n\u001b[1;32m    246\u001b[0m         font, size, index, encoding, layout_engine\u001b[38;5;241m=\u001b[39mlayout_engine\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mload_from_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/ImageFont.py:228\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__.<locals>.load_from_bytes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_bytes\u001b[39m(f):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont_bytes \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated.\n",
      "222\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "291\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "245\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "409\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "761\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "279\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "510\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "311\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "637\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "674\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "287\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "340\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "365\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "489\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "429\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "335\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "435\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "571\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "239\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "370\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "236\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "600\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "403\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "747\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "248\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "507\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "466\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "633\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "504\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "521\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "264\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "420\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "488\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "475\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "429\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "385\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "322\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "517\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "605\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "493\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "507\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "261\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "541\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "276\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "462\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "448\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "302\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "364\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "683\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "292\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "415\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "587\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "412\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "446\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "802\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "925\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  45.0\n",
      "first_0 reward: 22.0\n",
      "second_0 reward: 23.0\n",
      "Done.\n",
      "terminated.\n",
      "589\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "212\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "254\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "385\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "321\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "314\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "316\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "272\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "756\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 20.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "349\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "518\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "365\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "338\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "466\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "608\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 19.0\n",
      "Done.\n",
      "terminated.\n",
      "284\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "470\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "321\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "341\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "1080\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  42.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 23.0\n",
      "Done.\n",
      "terminated.\n",
      "848\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "346\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "585\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "702\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "391\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "446\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "540\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "378\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "581\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "652\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "322\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "342\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "589\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "514\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "513\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "588\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "408\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "676\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "634\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "463\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "297\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "579\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "295\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "508\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "450\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "430\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "299\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "498\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "371\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "424\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "544\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "424\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "372\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "397\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "298\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "313\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "505\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "685\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  34.0\n",
      "first_0 reward: 19.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "428\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "282\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "496\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "417\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "496\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "319\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "405\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "633\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "223\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "531\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "545\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "345\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "256\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "280\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "649\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "583\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "305\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "431\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "498\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "261\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "347\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "382\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "426\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "386\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "282\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "467\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "307\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "223\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "739\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "318\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "382\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "709\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  38.0\n",
      "first_0 reward: 23.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "466\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "266\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "270\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "256\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "256\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "358\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "454\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "615\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "315\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "629\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "528\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "337\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  4.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 0.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "362\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "482\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "348\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "375\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "391\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "349\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "385\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "519\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "299\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "670\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "387\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "588\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "448\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "255\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "389\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "488\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "263\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "653\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "632\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "526\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "483\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "258\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "515\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "519\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "381\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "346\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "409\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "317\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "531\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "376\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  21.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "510\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "254\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "502\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "249\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "506\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "575\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "306\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "270\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "418\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "461\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "261\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "582\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "406\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "338\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "420\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "781\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  33.0\n",
      "first_0 reward: 23.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "444\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "295\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "272\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "344\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "413\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "787\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "275\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "464\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "257\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "594\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "426\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "389\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "499\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "552\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "512\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "805\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 17.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "634\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "341\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "317\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "419\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "422\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 12.0\n",
      "Done.\n",
      "terminated.\n",
      "322\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "251\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 3.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "428\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "322\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "300\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "399\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "398\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "550\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "303\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "287\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "806\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "424\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "466\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "386\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "269\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "441\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "347\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "379\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "645\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  27.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "267\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "398\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "364\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "252\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "246\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "431\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "410\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "361\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "285\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "421\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  24.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "374\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "314\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  15.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "373\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "796\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 18.0\n",
      "Done.\n",
      "terminated.\n",
      "827\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  31.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "542\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "300\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "663\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  32.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "648\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  28.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "271\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 2.0\n",
      "Done.\n",
      "terminated.\n",
      "335\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "384\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "518\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "593\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "238\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "299\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "495\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "345\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "909\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  36.0\n",
      "first_0 reward: 16.0\n",
      "second_0 reward: 20.0\n",
      "Done.\n",
      "terminated.\n",
      "287\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "380\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "503\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  19.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "544\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 9.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "596\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "582\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "300\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "430\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "273\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "441\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "407\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "268\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "329\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "320\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "724\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  37.0\n",
      "first_0 reward: 20.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "491\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  20.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "270\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  9.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 3.0\n",
      "Done.\n",
      "terminated.\n",
      "315\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  10.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "325\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "450\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  18.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "392\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 8.0\n",
      "Done.\n",
      "terminated.\n",
      "494\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "616\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "291\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "273\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "251\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "549\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "648\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  30.0\n",
      "first_0 reward: 15.0\n",
      "second_0 reward: 15.0\n",
      "Done.\n",
      "terminated.\n",
      "422\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  13.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "276\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "383\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "900\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  35.0\n",
      "first_0 reward: 18.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "233\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  6.0\n",
      "first_0 reward: 1.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "475\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "438\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 8.0\n",
      "second_0 reward: 9.0\n",
      "Done.\n",
      "terminated.\n",
      "269\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  8.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 4.0\n",
      "Done.\n",
      "terminated.\n",
      "651\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  29.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 17.0\n",
      "Done.\n",
      "terminated.\n",
      "275\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "478\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  26.0\n",
      "first_0 reward: 13.0\n",
      "second_0 reward: 13.0\n",
      "Done.\n",
      "terminated.\n",
      "500\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 14.0\n",
      "second_0 reward: 11.0\n",
      "Done.\n",
      "terminated.\n",
      "422\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  17.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 10.0\n",
      "Done.\n",
      "terminated.\n",
      "253\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  7.0\n",
      "first_0 reward: 2.0\n",
      "second_0 reward: 5.0\n",
      "Done.\n",
      "terminated.\n",
      "521\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  23.0\n",
      "first_0 reward: 12.0\n",
      "second_0 reward: 11.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2/script-2-play.py:186\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m#print(os.path.join(gif_path, \"speaker_listener.gif\"))\u001b[39;00m\n\u001b[1;32m    185\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(gif_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 186\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#os.path.join(\"./videos/\", \"speaker_listener.gif\"), frames, duration=10\u001b[39;49;00m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgif_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspace_invaders_v2_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.gif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m    189\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/v2.py:494\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    493\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite(ims, is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/core/v3_plugin_api.py:367\u001b[0m, in \u001b[0;36mPluginV3.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/plugins/pillow.py:144\u001b[0m, in \u001b[0;36mPillowPlugin.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image:\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/plugins/pillow.py:485\u001b[0m, in \u001b[0;36mPillowPlugin._flush_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_all\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend_images\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_to_write\n\u001b[0;32m--> 485\u001b[0m \u001b[43mprimary_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_to_write\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_args\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/Image.py:2439\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2439\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py:704\u001b[0m, in \u001b[0;36m_save_all\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_all\u001b[39m(im, fp, filename):\n\u001b[0;32m--> 704\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py:715\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, save_all)\u001b[0m\n\u001b[1;32m    712\u001b[0m     palette \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     im\u001b[38;5;241m.\u001b[39mencoderinfo\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_all \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_write_multiple_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    716\u001b[0m     _write_single_frame(im, fp, palette)\n\u001b[1;32m    718\u001b[0m fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# end of file\u001b[39;00m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py:602\u001b[0m, in \u001b[0;36m_write_multiple_frames\u001b[0;34m(im, fp, palette)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imSequence \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain([im], im\u001b[38;5;241m.\u001b[39mencoderinfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend_images\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])):\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m im_frame \u001b[38;5;129;01min\u001b[39;00m ImageSequence\u001b[38;5;241m.\u001b[39mIterator(imSequence):\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;66;03m# a copy is required here since seek can still mutate the image\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m         im_frame \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m frame_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    604\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m im_frame\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py:492\u001b[0m, in \u001b[0;36m_normalize_mode\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mgetmodebase(im\u001b[38;5;241m.\u001b[39mmode) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 492\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPalette\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mADAPTIVE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rgba \u001b[38;5;129;01min\u001b[39;00m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mcolors:\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/Image.py:1029\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m palette \u001b[38;5;241m==\u001b[39m Palette\u001b[38;5;241m.\u001b[39mADAPTIVE:\n\u001b[0;32m-> 1029\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m     new_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(im)\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated.\n",
      "561\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  25.0\n",
      "first_0 reward: 11.0\n",
      "second_0 reward: 14.0\n",
      "Done.\n",
      "terminated.\n",
      "529\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  22.0\n",
      "first_0 reward: 6.0\n",
      "second_0 reward: 16.0\n",
      "Done.\n",
      "terminated.\n",
      "223\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  5.0\n",
      "first_0 reward: 4.0\n",
      "second_0 reward: 1.0\n",
      "Done.\n",
      "terminated.\n",
      "357\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  14.0\n",
      "first_0 reward: 7.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "247\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  12.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 7.0\n",
      "Done.\n",
      "terminated.\n",
      "290\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  11.0\n",
      "first_0 reward: 5.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n",
      "terminated.\n",
      "363\n",
      "--------------- Episode: 0 ---------------\n",
      "Episodic Reward:  16.0\n",
      "first_0 reward: 10.0\n",
      "second_0 reward: 6.0\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function PluginV3.__del__ at 0x7c7dcdd82200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/core/v3_plugin_api.py\", line 370, in __del__\n",
      "    self.close()\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/plugins/pillow.py\", line 144, in close\n",
      "    self._flush_writer()\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/imageio/plugins/pillow.py\", line 485, in _flush_writer\n",
      "    primary_image.save(self._request.get_file(), **self.save_args)\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/Image.py\", line 2439, in save\n",
      "    save_handler(self, fp, filename)\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py\", line 704, in _save_all\n",
      "    _save(im, fp, filename, save_all=True)\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py\", line 715, in _save\n",
      "    if not save_all or not _write_multiple_frames(im, fp, palette):\n",
      "  File \"/home/user/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/PIL/GifImagePlugin.py\", line 690, in _write_multiple_frames\n",
      "    fp.write(s)\n",
      "ValueError: write to closed file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/work-DRLSS2024/DRLSS2024-MultiAgent/otk/AgileRL-MATD3/space_invaders_v2/script-2-play.py:138\u001b[0m\n\u001b[1;32m    131\u001b[0m env_defined_actions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    132\u001b[0m     info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_defined_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_defined_actions\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Get next action from agent\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m cont_actions, discrete_action \u001b[38;5;241m=\u001b[39m \u001b[43mmatd3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetAction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_defined_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_defined_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matd3\u001b[38;5;241m.\u001b[39mdiscrete_actions:\n\u001b[1;32m    145\u001b[0m     action \u001b[38;5;241m=\u001b[39m discrete_action\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/agilerl/algorithms/matd3.py:416\u001b[0m, in \u001b[0;36mMATD3.getAction\u001b[0;34m(self, states, epsilon, agent_mask, env_defined_actions)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 416\u001b[0m         action_values \u001b[38;5;241m=\u001b[39m \u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m actor\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscrete_actions:\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/agilerl/networks/evolvable_cnn.py:507\u001b[0m, in \u001b[0;36mEvolvableCNN.forward\u001b[0;34m(self, x, xc, q)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[1;32m    505\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m--> 507\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic:\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work-DRLSS2024/venv-DRLSS2024/lib/python3.10/site-packages/torch/nn/modules/conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%run script-2-play.py -dt $str_dt_now\n",
    "#for _ in range(20):\n",
    "while True:\n",
    "    %run script-2-play.py -dt \"20240325-0509\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd62d1b5-7785-4023-8de1-0ff1f36b4239",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'playsound'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     playsound\u001b[38;5;241m.\u001b[39mplaysound(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfireworks.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'playsound'"
     ]
    }
   ],
   "source": [
    "import playsound\n",
    "\n",
    "while True:\n",
    "    playsound.playsound(\"fireworks.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75d986-de09-4449-ab01-394fcb3ce289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399259e0-3c85-4800-b574-e7f08d86b9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
